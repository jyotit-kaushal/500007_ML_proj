{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "# Week 10 Problem Set\n",
                "\n",
                "## Cohort Session"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS0.** Do the following tasks before you start with the first cohort session.\n",
                "\n",
                "**Task 1.** Paste the following functions from your previous work:\n",
                "- `get_features_targets()`\n",
                "- `normalize_z()`\n",
                "- `prepare_feature()`\n",
                "- `prepare_target()`\n",
                "- `split_data()`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs01",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def normalize_z(df):\n",
                "    ### BEGIN SOLUTION\n",
                "    dfout = df.copy()\n",
                "    dfout = (df - df.mean(axis=0)) / df.std(axis=0)\n",
                "    return dfout\n",
                "    ### END SOLUTION\n",
                "    pass\n",
                "\n",
                "def get_features_targets(df, feature_names, target_names):\n",
                "    ### BEGIN SOLUTION\n",
                "    df_feature = df[feature_names]\n",
                "    df_target = df[target_names]\n",
                "    ### END SOLUTION\n",
                "    pass\n",
                "    return df_feature, df_target\n",
                "\n",
                "def prepare_feature(df_feature): # X matrix: # rows -> # samples, # cols -> # features\n",
                "    ### BEGIN SOLUTION\n",
                "    cols = len(df_feature.columns)\n",
                "    feature = df_feature.to_numpy().reshape(-1, cols)\n",
                "    X = np.concatenate((np.ones((feature.shape[0],1)), feature), axis=1)\n",
                "    return X\n",
                "    ### END SOLUTION\n",
                "    pass\n",
                "\n",
                "def prepare_target(df_target):\n",
                "    ### BEGIN SOLUTION\n",
                "    cols = len(df_target.columns)\n",
                "    target = df_target.to_numpy().reshape(-1, cols)\n",
                "    return target\n",
                "    ### END SOLUTION\n",
                "    pass\n",
                "\n",
                "def split_data(df_feature, df_target, random_state=None, test_size=0.5):\n",
                "    ### BEGIN SOLUTION\n",
                "    indexes = df_feature.index\n",
                "    if random_state != None:\n",
                "        np.random.seed(random_state)\n",
                "    k = int(test_size * len(indexes))\n",
                "    test_index = np.random.choice(indexes, k, replace=False)\n",
                "    indexes = set(indexes)\n",
                "    test_index = set(test_index)\n",
                "    train_index = indexes - test_index\n",
                "    df_feature_train = df_feature.loc[train_index, :]\n",
                "    df_feature_test = df_feature.loc[test_index, :]\n",
                "    df_target_train = df_target.loc[train_index, :]\n",
                "    df_target_test = df_target.loc[test_index, :]\n",
                "    ### END SOLUTION\n",
                "    return df_feature_train, df_feature_test, df_target_train, df_target_test\n",
                " "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**Task 2.** Load the breast cancer data from `breast_cancer_data.csv` into a Data Frame. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs02",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>diagnosis</th>\n",
                            "      <th>radius_mean</th>\n",
                            "      <th>texture_mean</th>\n",
                            "      <th>perimeter_mean</th>\n",
                            "      <th>area_mean</th>\n",
                            "      <th>smoothness_mean</th>\n",
                            "      <th>compactness_mean</th>\n",
                            "      <th>concavity_mean</th>\n",
                            "      <th>concave points_mean</th>\n",
                            "      <th>...</th>\n",
                            "      <th>radius_worst</th>\n",
                            "      <th>texture_worst</th>\n",
                            "      <th>perimeter_worst</th>\n",
                            "      <th>area_worst</th>\n",
                            "      <th>smoothness_worst</th>\n",
                            "      <th>compactness_worst</th>\n",
                            "      <th>concavity_worst</th>\n",
                            "      <th>concave points_worst</th>\n",
                            "      <th>symmetry_worst</th>\n",
                            "      <th>fractal_dimension_worst</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>842302</td>\n",
                            "      <td>M</td>\n",
                            "      <td>17.99</td>\n",
                            "      <td>10.38</td>\n",
                            "      <td>122.80</td>\n",
                            "      <td>1001.0</td>\n",
                            "      <td>0.11840</td>\n",
                            "      <td>0.27760</td>\n",
                            "      <td>0.30010</td>\n",
                            "      <td>0.14710</td>\n",
                            "      <td>...</td>\n",
                            "      <td>25.380</td>\n",
                            "      <td>17.33</td>\n",
                            "      <td>184.60</td>\n",
                            "      <td>2019.0</td>\n",
                            "      <td>0.16220</td>\n",
                            "      <td>0.66560</td>\n",
                            "      <td>0.7119</td>\n",
                            "      <td>0.2654</td>\n",
                            "      <td>0.4601</td>\n",
                            "      <td>0.11890</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>842517</td>\n",
                            "      <td>M</td>\n",
                            "      <td>20.57</td>\n",
                            "      <td>17.77</td>\n",
                            "      <td>132.90</td>\n",
                            "      <td>1326.0</td>\n",
                            "      <td>0.08474</td>\n",
                            "      <td>0.07864</td>\n",
                            "      <td>0.08690</td>\n",
                            "      <td>0.07017</td>\n",
                            "      <td>...</td>\n",
                            "      <td>24.990</td>\n",
                            "      <td>23.41</td>\n",
                            "      <td>158.80</td>\n",
                            "      <td>1956.0</td>\n",
                            "      <td>0.12380</td>\n",
                            "      <td>0.18660</td>\n",
                            "      <td>0.2416</td>\n",
                            "      <td>0.1860</td>\n",
                            "      <td>0.2750</td>\n",
                            "      <td>0.08902</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>84300903</td>\n",
                            "      <td>M</td>\n",
                            "      <td>19.69</td>\n",
                            "      <td>21.25</td>\n",
                            "      <td>130.00</td>\n",
                            "      <td>1203.0</td>\n",
                            "      <td>0.10960</td>\n",
                            "      <td>0.15990</td>\n",
                            "      <td>0.19740</td>\n",
                            "      <td>0.12790</td>\n",
                            "      <td>...</td>\n",
                            "      <td>23.570</td>\n",
                            "      <td>25.53</td>\n",
                            "      <td>152.50</td>\n",
                            "      <td>1709.0</td>\n",
                            "      <td>0.14440</td>\n",
                            "      <td>0.42450</td>\n",
                            "      <td>0.4504</td>\n",
                            "      <td>0.2430</td>\n",
                            "      <td>0.3613</td>\n",
                            "      <td>0.08758</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>84348301</td>\n",
                            "      <td>M</td>\n",
                            "      <td>11.42</td>\n",
                            "      <td>20.38</td>\n",
                            "      <td>77.58</td>\n",
                            "      <td>386.1</td>\n",
                            "      <td>0.14250</td>\n",
                            "      <td>0.28390</td>\n",
                            "      <td>0.24140</td>\n",
                            "      <td>0.10520</td>\n",
                            "      <td>...</td>\n",
                            "      <td>14.910</td>\n",
                            "      <td>26.50</td>\n",
                            "      <td>98.87</td>\n",
                            "      <td>567.7</td>\n",
                            "      <td>0.20980</td>\n",
                            "      <td>0.86630</td>\n",
                            "      <td>0.6869</td>\n",
                            "      <td>0.2575</td>\n",
                            "      <td>0.6638</td>\n",
                            "      <td>0.17300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>84358402</td>\n",
                            "      <td>M</td>\n",
                            "      <td>20.29</td>\n",
                            "      <td>14.34</td>\n",
                            "      <td>135.10</td>\n",
                            "      <td>1297.0</td>\n",
                            "      <td>0.10030</td>\n",
                            "      <td>0.13280</td>\n",
                            "      <td>0.19800</td>\n",
                            "      <td>0.10430</td>\n",
                            "      <td>...</td>\n",
                            "      <td>22.540</td>\n",
                            "      <td>16.67</td>\n",
                            "      <td>152.20</td>\n",
                            "      <td>1575.0</td>\n",
                            "      <td>0.13740</td>\n",
                            "      <td>0.20500</td>\n",
                            "      <td>0.4000</td>\n",
                            "      <td>0.1625</td>\n",
                            "      <td>0.2364</td>\n",
                            "      <td>0.07678</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>564</th>\n",
                            "      <td>926424</td>\n",
                            "      <td>M</td>\n",
                            "      <td>21.56</td>\n",
                            "      <td>22.39</td>\n",
                            "      <td>142.00</td>\n",
                            "      <td>1479.0</td>\n",
                            "      <td>0.11100</td>\n",
                            "      <td>0.11590</td>\n",
                            "      <td>0.24390</td>\n",
                            "      <td>0.13890</td>\n",
                            "      <td>...</td>\n",
                            "      <td>25.450</td>\n",
                            "      <td>26.40</td>\n",
                            "      <td>166.10</td>\n",
                            "      <td>2027.0</td>\n",
                            "      <td>0.14100</td>\n",
                            "      <td>0.21130</td>\n",
                            "      <td>0.4107</td>\n",
                            "      <td>0.2216</td>\n",
                            "      <td>0.2060</td>\n",
                            "      <td>0.07115</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>565</th>\n",
                            "      <td>926682</td>\n",
                            "      <td>M</td>\n",
                            "      <td>20.13</td>\n",
                            "      <td>28.25</td>\n",
                            "      <td>131.20</td>\n",
                            "      <td>1261.0</td>\n",
                            "      <td>0.09780</td>\n",
                            "      <td>0.10340</td>\n",
                            "      <td>0.14400</td>\n",
                            "      <td>0.09791</td>\n",
                            "      <td>...</td>\n",
                            "      <td>23.690</td>\n",
                            "      <td>38.25</td>\n",
                            "      <td>155.00</td>\n",
                            "      <td>1731.0</td>\n",
                            "      <td>0.11660</td>\n",
                            "      <td>0.19220</td>\n",
                            "      <td>0.3215</td>\n",
                            "      <td>0.1628</td>\n",
                            "      <td>0.2572</td>\n",
                            "      <td>0.06637</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>566</th>\n",
                            "      <td>926954</td>\n",
                            "      <td>M</td>\n",
                            "      <td>16.60</td>\n",
                            "      <td>28.08</td>\n",
                            "      <td>108.30</td>\n",
                            "      <td>858.1</td>\n",
                            "      <td>0.08455</td>\n",
                            "      <td>0.10230</td>\n",
                            "      <td>0.09251</td>\n",
                            "      <td>0.05302</td>\n",
                            "      <td>...</td>\n",
                            "      <td>18.980</td>\n",
                            "      <td>34.12</td>\n",
                            "      <td>126.70</td>\n",
                            "      <td>1124.0</td>\n",
                            "      <td>0.11390</td>\n",
                            "      <td>0.30940</td>\n",
                            "      <td>0.3403</td>\n",
                            "      <td>0.1418</td>\n",
                            "      <td>0.2218</td>\n",
                            "      <td>0.07820</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>567</th>\n",
                            "      <td>927241</td>\n",
                            "      <td>M</td>\n",
                            "      <td>20.60</td>\n",
                            "      <td>29.33</td>\n",
                            "      <td>140.10</td>\n",
                            "      <td>1265.0</td>\n",
                            "      <td>0.11780</td>\n",
                            "      <td>0.27700</td>\n",
                            "      <td>0.35140</td>\n",
                            "      <td>0.15200</td>\n",
                            "      <td>...</td>\n",
                            "      <td>25.740</td>\n",
                            "      <td>39.42</td>\n",
                            "      <td>184.60</td>\n",
                            "      <td>1821.0</td>\n",
                            "      <td>0.16500</td>\n",
                            "      <td>0.86810</td>\n",
                            "      <td>0.9387</td>\n",
                            "      <td>0.2650</td>\n",
                            "      <td>0.4087</td>\n",
                            "      <td>0.12400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>568</th>\n",
                            "      <td>92751</td>\n",
                            "      <td>B</td>\n",
                            "      <td>7.76</td>\n",
                            "      <td>24.54</td>\n",
                            "      <td>47.92</td>\n",
                            "      <td>181.0</td>\n",
                            "      <td>0.05263</td>\n",
                            "      <td>0.04362</td>\n",
                            "      <td>0.00000</td>\n",
                            "      <td>0.00000</td>\n",
                            "      <td>...</td>\n",
                            "      <td>9.456</td>\n",
                            "      <td>30.37</td>\n",
                            "      <td>59.16</td>\n",
                            "      <td>268.6</td>\n",
                            "      <td>0.08996</td>\n",
                            "      <td>0.06444</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.0000</td>\n",
                            "      <td>0.2871</td>\n",
                            "      <td>0.07039</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>569 rows × 32 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
                            "0      842302         M        17.99         10.38          122.80     1001.0   \n",
                            "1      842517         M        20.57         17.77          132.90     1326.0   \n",
                            "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
                            "3    84348301         M        11.42         20.38           77.58      386.1   \n",
                            "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
                            "..        ...       ...          ...           ...             ...        ...   \n",
                            "564    926424         M        21.56         22.39          142.00     1479.0   \n",
                            "565    926682         M        20.13         28.25          131.20     1261.0   \n",
                            "566    926954         M        16.60         28.08          108.30      858.1   \n",
                            "567    927241         M        20.60         29.33          140.10     1265.0   \n",
                            "568     92751         B         7.76         24.54           47.92      181.0   \n",
                            "\n",
                            "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
                            "0            0.11840           0.27760         0.30010              0.14710   \n",
                            "1            0.08474           0.07864         0.08690              0.07017   \n",
                            "2            0.10960           0.15990         0.19740              0.12790   \n",
                            "3            0.14250           0.28390         0.24140              0.10520   \n",
                            "4            0.10030           0.13280         0.19800              0.10430   \n",
                            "..               ...               ...             ...                  ...   \n",
                            "564          0.11100           0.11590         0.24390              0.13890   \n",
                            "565          0.09780           0.10340         0.14400              0.09791   \n",
                            "566          0.08455           0.10230         0.09251              0.05302   \n",
                            "567          0.11780           0.27700         0.35140              0.15200   \n",
                            "568          0.05263           0.04362         0.00000              0.00000   \n",
                            "\n",
                            "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
                            "0    ...        25.380          17.33           184.60      2019.0   \n",
                            "1    ...        24.990          23.41           158.80      1956.0   \n",
                            "2    ...        23.570          25.53           152.50      1709.0   \n",
                            "3    ...        14.910          26.50            98.87       567.7   \n",
                            "4    ...        22.540          16.67           152.20      1575.0   \n",
                            "..   ...           ...            ...              ...         ...   \n",
                            "564  ...        25.450          26.40           166.10      2027.0   \n",
                            "565  ...        23.690          38.25           155.00      1731.0   \n",
                            "566  ...        18.980          34.12           126.70      1124.0   \n",
                            "567  ...        25.740          39.42           184.60      1821.0   \n",
                            "568  ...         9.456          30.37            59.16       268.6   \n",
                            "\n",
                            "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
                            "0             0.16220            0.66560           0.7119   \n",
                            "1             0.12380            0.18660           0.2416   \n",
                            "2             0.14440            0.42450           0.4504   \n",
                            "3             0.20980            0.86630           0.6869   \n",
                            "4             0.13740            0.20500           0.4000   \n",
                            "..                ...                ...              ...   \n",
                            "564           0.14100            0.21130           0.4107   \n",
                            "565           0.11660            0.19220           0.3215   \n",
                            "566           0.11390            0.30940           0.3403   \n",
                            "567           0.16500            0.86810           0.9387   \n",
                            "568           0.08996            0.06444           0.0000   \n",
                            "\n",
                            "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
                            "0                  0.2654          0.4601                  0.11890  \n",
                            "1                  0.1860          0.2750                  0.08902  \n",
                            "2                  0.2430          0.3613                  0.08758  \n",
                            "3                  0.2575          0.6638                  0.17300  \n",
                            "4                  0.1625          0.2364                  0.07678  \n",
                            "..                    ...             ...                      ...  \n",
                            "564                0.2216          0.2060                  0.07115  \n",
                            "565                0.1628          0.2572                  0.06637  \n",
                            "566                0.1418          0.2218                  0.07820  \n",
                            "567                0.2650          0.4087                  0.12400  \n",
                            "568                0.0000          0.2871                  0.07039  \n",
                            "\n",
                            "[569 rows x 32 columns]"
                        ]
                    },
                    "execution_count": 46,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# read breast_cancer_data.csv\n",
                "df = pd.read_csv('breast_cancer_data.csv')\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "\n",
                "df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**Task 3.** Do the following tasks.\n",
                "\n",
                "- Read the following columns\n",
                "    - feature: `radius_mean`\n",
                "    - target: `diagnosis`\n",
                "- Normalize the feature column using z normalization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs03",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "# extract the feature and the target\n",
                "df_feature, df_target = get_features_targets(df, ['radius_mean'], ['diagnosis'])\n",
                "\n",
                "# normalize the feature\n",
                "df_feature = normalize_z(df_feature)\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**Task 4.** Write a function `replace_target()` to replace the `diagnosis` column with the following mapping:\n",
                "    - `M`: `1`, this means that malignant cell are indicated as `1` in our new column.\n",
                "    - `B`: `0`, this means that benign cell are indicated as `0` in our new column.\n",
                "    \n",
                "The function should takes in the following:\n",
                "\n",
                "- `df_target`: the target data frame\n",
                "- `target_name`: which is the column name of the target data frame\n",
                "- `map`: which is a dictionary containing the map\n",
                "    \n",
                "It should returns a new data frame with the same column name but with its values changed according to the mapping."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs04",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def replace_target(df_target, target_name, map_vals):\n",
                "    df_copy = df_target.copy()\n",
                "    df_copy.loc[:, target_name]= df_target[target_name].apply(lambda x: map_vals[x])\n",
                "    return df_copy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>diagnosis</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>564</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>565</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>566</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>567</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>568</th>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>569 rows × 1 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "     diagnosis\n",
                            "0            1\n",
                            "1            1\n",
                            "2            1\n",
                            "3            1\n",
                            "4            1\n",
                            "..         ...\n",
                            "564          1\n",
                            "565          1\n",
                            "566          1\n",
                            "567          1\n",
                            "568          0\n",
                            "\n",
                            "[569 rows x 1 columns]"
                        ]
                    },
                    "execution_count": 49,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df_target = replace_target(df_target, \"diagnosis\", {'M': 1, 'B': 0})\n",
                "df_target"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**Task 5.** Do the following tasks.\n",
                "- Change feature to Numpy array and append constant 1 column.\n",
                "- Change target to Numpy array"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs05",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "# change feature data frame to numpy array and append column 1\n",
                "feature = prepare_feature(df_feature)\n",
                "\n",
                "# change target data frame to numpy array\n",
                "target = prepare_feature(df_target)\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS1.** *Logistic function:* Write a function to calculate the hypothesis using a logistic function. Recall that the hypothesis for a logistic regression model is written as:\n",
                "\n",
                "$$\\mathbf{p}(x) = \\frac{1}{1 + e^{-\\mathbf{X}\\mathbf{b}}}$$\n",
                "\n",
                "The shape of the input is as follows:\n",
                "- $\\mathbf{b}$: is a column vector for the parameters\n",
                "- $\\mathbf{X}$: is a matrix where the number of rows are the number of data points and the the number of columns must the same as the number of parameters in $\\mathbf{b}$.\n",
                "\n",
                "Note that you need to ensure that the output is a **column vector**. \n",
                "\n",
                "You can use the following functions:\n",
                "- `np.matmul(array1, array2)`: which is to perform matrix multiplication on the two numpy arrays.\n",
                "- `np.exp()`: which is to calculate the function $e^x$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs11",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def log_regression(beta, X): # prediction, output is between 0 and 1\n",
                "    ### BEGIN SOLUTION\n",
                "    return 1/(1+np.exp(np.matmul(X, -beta)))\n",
                "    ### END SOLUTION\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs11",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "beta = np.array([0])\n",
                "x = np.array([0])\n",
                "ans = log_regression(beta, x)\n",
                "assert ans == 0.5\n",
                "\n",
                "beta = np.array([2])\n",
                "x = np.array([40])\n",
                "ans = log_regression(beta, x)\n",
                "assert np.isclose(ans, 1.0)\n",
                "\n",
                "beta = np.array([2])\n",
                "x = np.array([-40])\n",
                "ans = log_regression(beta, x)\n",
                "assert np.isclose(ans, 0.0)\n",
                "\n",
                "beta = np.array([[1, 2, 3]])\n",
                "x = np.array([[3, 2, 1]])\n",
                "ans = log_regression(beta.T, x)\n",
                "assert np.isclose(ans.all(), 1.0)\n",
                "\n",
                "beta = np.array([[1, 2, 3]])\n",
                "x = np.array([[3, 2, 1], [3, 2, 1]])\n",
                "ans = log_regression(beta.T, x)\n",
                "assert ans.shape == (2, 1)\n",
                "assert np.isclose(ans.all(), 1.0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs12",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS2.** *Cost Function:* Write a function to calculate the cost function for logistic regression. Recall that the cost function for logistic regression is given by:\n",
                "\n",
                "$$J(\\beta) = -\\frac{1}{m}\\left[\\Sigma_{i=1}^m y^i \\log(p(x^i)) + (1 - y^i) \\log(1 - p(x^i))\\right]$$\n",
                "\n",
                "You can use the following function in your code:\n",
                "- `np.where(condition, then_expression, else_expression)`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs13",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def compute_cost_logreg(beta, X, y):\n",
                "    np.seterr(divide = 'ignore') \n",
                "    ### BEGIN SOLUTION\n",
                "    num_of_samples = len(y)\n",
                "    J = -(1/num_of_samples) * \\\n",
                "        np.sum(np.where(y==1, np.log(log_regression(beta,X)), np.log(1-log_regression(beta,X))))\n",
                "    ### END SOLUTION\n",
                "    np.seterr(divide = 'warn')\n",
                "    return J"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs21",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "-0.0\n",
                        "-0.0\n"
                    ]
                }
            ],
            "source": [
                "y = np.array([[1]])\n",
                "X = np.array([[10, 40]])\n",
                "beta = np.array([1, 1]).T\n",
                "ans = compute_cost_logreg(beta, X, y)\n",
                "print(ans)\n",
                "assert np.isclose(ans, 0)\n",
                "\n",
                "y = np.array([[0]])\n",
                "X = np.array([[10, 40]])\n",
                "beta = np.array([[-1, -1]]).T\n",
                "ans = compute_cost_logreg(beta, X, y)\n",
                "print(ans)\n",
                "assert np.isclose(ans, 0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs22",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS3.** *Gradient Descent:* Recall that the update functions can be written as a matrix multiplication.\n",
                "\n",
                "$$\\mathbf{b} = \\mathbf{b} - \\alpha\\frac{1}{m}\\mathbf{X}^T(\\mathbf{p} - \\mathbf{y}) $$\n",
                "\n",
                "Write a function called `gradient_descent_logreg()` that takes in five parameters:\n",
                "- `X`: is a 2-D numpy array for the features\n",
                "- `y`: is a vector array for the target\n",
                "- `beta`: is a column vector for the initial guess of the parameters\n",
                "- `alpha`: is the learning rate\n",
                "- `num_iters`: is the number of iteration to perform\n",
                "\n",
                "The function should return two arrays:\n",
                "- `beta`: is coefficient at the end of the iteration\n",
                "- `J_storage`: is the array that stores the cost value at each iteration\n",
                "\n",
                "The solution is similar to Linear Regression gradient descent function with two differences:\n",
                "- you need to use `log_regression()` to calculate the hypothesis\n",
                "- you need to use `compute_cost_logreg()` to calculate the cost"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs31",
                    "locked": false,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def gradient_descent_logreg(X, y, beta, alpha, num_iters):\n",
                "    m = X.shape[0] # number of samples\n",
                "    J_storage = np.zeros((num_iters,1))\n",
                "    for i in range(num_iters):\n",
                "        derivative = (1/m) * np.matmul(X.T, (log_regression(beta, X) - y))\n",
                "        beta = beta - alpha * derivative # update the beta \n",
                "        J_storage[i] = compute_cost_logreg(beta, X, y) \n",
                "    return beta, J_storage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs31",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[[ 2.59626982e+00 -5.66302894e-01]\n",
                        " [-3.29776433e-15  1.93763591e+00]]\n"
                    ]
                },
                {
                    "ename": "AssertionError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/yy/rcnbsh9d65s6m7lnl3jl85lw0000gn/T/ipykernel_1688/1257262746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.56630\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.93764\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAssertionError\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "iterations = 1500\n",
                "alpha = 0.01\n",
                "beta = np.zeros((2,1))\n",
                "beta, J_storage = gradient_descent_logreg(feature, target, beta, alpha, iterations)\n",
                "\n",
                "print(beta)\n",
                "assert beta.shape == (2, 1)\n",
                "assert np.isclose(beta[0][0], -0.56630)\n",
                "assert np.isclose(beta[1][0], 1.93764)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs32",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[<matplotlib.lines.Line2D at 0x7fddf20286d0>]"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.plot(J_storage)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS4.** *Predict:* Write two functions `predict()` and `predict_norm()` that calculate the straight line equation given the features and its coefficient.\n",
                "- `predict()`: this function should standardize the feature using z normalization, change it to a Numpy array, and add a column of constant 1s. You should use `prepare_feature()` for this purpose. Lastly, this function should also call `predict_norm()` to get the predicted y values.\n",
                "- `predict_norm()`: this function should calculate the straight line equation after standardization and adding of column for constant 1.\n",
                "\n",
                "You can use the following function in your code:\n",
                "- `np.where()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def predict_norm(X, beta):\n",
                "    p = log_regression(beta, X)\n",
                "    return np.where(p>=0.5, 1, 0)\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def predict(df_feature, beta):\n",
                "    X = prepare_feature(df_feature)\n",
                "    return predict_norm(X, beta)\n",
                "    pass"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs41",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.6449912126537786 0.47851598536850026\n"
                    ]
                },
                {
                    "ename": "AssertionError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/yy/rcnbsh9d65s6m7lnl3jl85lw0000gn/T/ipykernel_1688/2985908949.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.28998\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.45375\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAssertionError\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "pred = predict(df_feature, beta)\n",
                "print(pred.mean(), pred.std())\n",
                "assert isinstance(pred, np.ndarray)\n",
                "assert np.isclose(pred.mean(), 0.28998)\n",
                "assert np.isclose(pred.std(), 0.45375)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs42",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [
                {
                    "ename": "ValueError",
                    "evalue": "x and y must be the same size",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/yy/rcnbsh9d65s6m7lnl3jl85lw0000gn/T/ipykernel_1688/357055468.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 3068\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   3069\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4496\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ]
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": [
                "plt.scatter(df_feature, df_target)\n",
                "plt.scatter(df_feature, pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS5.** *Multiple features and splitting of data set:* \n",
                "\n",
                "Do the following task in the code below:\n",
                "- Read the following column names as the features: `\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\"`\n",
                "- Read the column `diagnosis` as the target. Change the value from `M` and `B` to `1` and `0` respectively.\n",
                "- Split the data set with 30% test size and `random_state = 100`.\n",
                "- Normalize the training feature data set using `normalize_z()` function.\n",
                "- Convert to numpy array both the target and the features using `prepare_feature()` and `prepare_target()` functions.\n",
                "- Call `gradient_descent()` function to get the parameters using the training data set.\n",
                "- Call `predict()` function on the test data set to get the predicted values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "get_features_targets() missing 2 required positional arguments: 'feature_names' and 'target_names'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/yy/rcnbsh9d65s6m7lnl3jl85lw0000gn/T/ipykernel_1688/1159325925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# extract the features and the target columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# replace the target values using from string to integer 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: get_features_targets() missing 2 required positional arguments: 'feature_names' and 'target_names'"
                    ]
                }
            ],
            "source": [
                "columns = [\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\"]\n",
                "\n",
                "# extract the features and the target columns\n",
                "df_features, df_target = get_features_targets(df, )\n",
                "\n",
                "# replace the target values using from string to integer 0 and 1\n",
                "df_target = None\n",
                "\n",
                "# split the data with random_state = 100 and 30% test size\n",
                "df_features_train, df_features_test, df_target_train, df_target_test = None, None, None, None\n",
                "\n",
                "# normalize the features\n",
                "df_features_train_z = None\n",
                "\n",
                "# change the feature columns to numpy array and append column of 1s\n",
                "features = None\n",
                "\n",
                "# change the target column to numpy array\n",
                "target = None\n",
                "\n",
                "iterations = 1500\n",
                "alpha = 0.01\n",
                "\n",
                "# provide initial guess for theta\n",
                "beta = None\n",
                "\n",
                "# call the gradient descent method\n",
                "beta, J_storage = None, None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n",
                "print(beta)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs51",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [
                {
                    "ename": "AssertionError",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[0;32m/var/folders/yy/rcnbsh9d65s6m7lnl3jl85lw0000gn/T/ipykernel_1688/2245297645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m ans = np.array([[-0.6139379 ], \n\u001b[1;32m      3\u001b[0m                 \u001b[0;34m[\u001b[0m \u001b[0;36m0.82529554\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0;34m[\u001b[0m \u001b[0;36m0.72746485\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m[\u001b[0m \u001b[0;36m0.8236603\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mAssertionError\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "assert beta.shape == (8, 1)\n",
                "ans = np.array([[-0.6139379 ], \n",
                "                [ 0.82529554],\n",
                "                [ 0.72746485],\n",
                "                [ 0.8236603 ],\n",
                "                [ 0.81647937],\n",
                "                [ 0.5057749 ],\n",
                "                [ 0.44176466],\n",
                "                [ 0.78736842]])\n",
                "assert np.isclose(beta, ans).all()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs52",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.plot(J_storage)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# call predict() to get the predicted values\n",
                "pred = predict(df_features_test, beta)\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test[\"radius_mean\"], df_target_test)\n",
                "plt.scatter(df_features_test[\"radius_mean\"], pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test[\"texture_mean\"], df_target_test)\n",
                "plt.scatter(df_features_test[\"texture_mean\"], pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test[\"perimeter_mean\"], df_target_test)\n",
                "plt.scatter(df_features_test[\"perimeter_mean\"], pred)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS6.** *Confusion Matrix:* Write a function `confusion_matrix()` that takes in:\n",
                "- `ytrue`: which is the true target values\n",
                "- `ypred`: which is the predicted target values\n",
                "- `labels`: which is a list of the category. In the above case it will be `[1, 0]`. Put the positive case as the first element of the list. \n",
                "\n",
                "The function should return a dictionary containing the matrix with the following format.\n",
                "\n",
                "|                 | predicted positive (1) | predicted negative (0) |\n",
                "|-----------------|--------------------|--------------------|\n",
                "| actual positive (1) | correct positive  (1, 1) | false negative (1, 0)    |\n",
                "| actual negative (0) | false positive (0, 1)   | correct negative (0, 0)   |\n",
                "\n",
                "The keys to the dictionary are the indices: `(0, 0), (0, 1), (1, 0), (1, 1)`.\n",
                "\n",
                "You can use the following function in your code:\n",
                "- `itertools.product()`: this is to create a combination of all the labels. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "import itertools\n",
                "def confusion_matrix(ytrue, ypred, labels):\n",
                "    output = {}\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    return output\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs61",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "result = confusion_matrix(df_target_test.values, pred, [1,0])\n",
                "print(result)\n",
                "assert result == {(0, 0): 100, (0, 1): 1, (1, 0): 12, (1, 1): 57}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS7.** *Metrics:* Write a function `calc_accuracy()` that takes in a Confusion Matrix array and output a dictionary with the following keys and values:\n",
                "- `accuracy`: total number of correct predictions / total number of records\n",
                "- `sensitivity`: total correct positive cases / total positive cases\n",
                "- `specificity`: total false positives / total negative cases\n",
                "- `precision`: total  of correct positive cases / total predicted positive cases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def calc_accuracy(cm):\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    result = {'accuracy': accuracy, 'sensitivity': sensitivity,\n",
                "              'specificity': specificity, 'precision': precision}\n",
                "    return result\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cs71",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "ans = calc_accuracy(result)\n",
                "expected = {'accuracy': 0.9235294117647059, 'sensitivity': 0.8260869565217391, 'specificity': 0.9900990099009901, 'precision': 0.9827586206896551}\n",
                "assert np.isclose(ans['accuracy'], expected['accuracy'])\n",
                "assert np.isclose(ans['sensitivity'], expected['sensitivity'])\n",
                "assert np.isclose(ans['specificity'], expected['specificity'])\n",
                "assert np.isclose(ans['precision'], expected['precision'])\n",
                " "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "source": [
                "**CS8.** *Optional:* Redo the above tasks using Scikit Learn libraries. You will need to use the following:\n",
                "- [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
                "- [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
                "- [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import confusion_matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "columns = [\"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \"compactness_mean\", \"concavity_mean\"]\n",
                "# get the features and the columns\n",
                "df_features = None\n",
                "\n",
                "# replace target values with 0 and 1\n",
                "df_target = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# split data set using random_state = 100 and 30% test size\n",
                "df_features_train, df_features_test, df_target_train, df_target_test = None, None, None, None\n",
                "\n",
                "# change feature to numpy array and append column of 1s\n",
                "feature = None\n",
                "\n",
                "# change target to numpy array\n",
                "target = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# create LogisticRegression object instance, use newton-cg solver\n",
                "model = LogisticRegression(solver = 'newton-cg')\n",
                "\n",
                "# build model\n",
                "model.fit(df_features_train, target.flatten())\n",
                "pass\n",
                "\n",
                "# get predicted value\n",
                "pred = model.predict(df_features_test)\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "# calculate confusion matrix\n",
                "cm = None\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cs81",
                    "locked": true,
                    "points": "1",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "expected = np.array([[58,  11], [6, 96]])\n",
                "assert (cm == expected).all()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test[\"radius_mean\"], df_target_test)\n",
                "plt.scatter(df_features_test[\"radius_mean\"], pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test[\"texture_mean\"], df_target_test)\n",
                "plt.scatter(df_features_test[\"texture_mean\"], pred)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "deletable": false,
                "editable": false,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "plt.scatter(df_features_test[\"perimeter_mean\"], df_target_test)\n",
                "plt.scatter(df_features_test[\"perimeter_mean\"], pred)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.7 64-bit ('base': conda)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.7"
        },
        "vscode": {
            "interpreter": {
                "hash": "d264375431ec867ce4451d87186e33c8c664431a37240a06155db17d375e3c4c"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
