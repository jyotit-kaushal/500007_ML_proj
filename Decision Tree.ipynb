{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17184, 5002)\n"
     ]
    }
   ],
   "source": [
    "filename = '50007-2022/train_tfidf_features.csv'\n",
    "train_features = pd.read_csv (filename, header=0)\n",
    "\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  label    0    1    2    3    4    5    6    7  ...  4990  4991  4992  \\\n",
      "0   1      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "1   2      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2   3      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3   4      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4   5      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5   6      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6   7      0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7   8      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8   9      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9  10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "   4993  4994  4995  4996  4997  4998  4999  \n",
      "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5002 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label    0    1    2    3    4    5    6    7    8  ...  4990  4991  4992  \\\n",
      "id                                                      ...                     \n",
      "1       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "2       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "3       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "4       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "5       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "6       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "7       0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "8       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "9       1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "10      1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
      "\n",
      "    4993  4994  4995  4996  4997  4998  4999  \n",
      "id                                            \n",
      "1    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "5    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "6    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "7    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "8    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "9    0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "10   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[10 rows x 5001 columns]\n"
     ]
    }
   ],
   "source": [
    "train_features.set_index('id', inplace=True, drop=True)\n",
    "print(train_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
    "        ''' constructor ''' \n",
    "        \n",
    "        ## which feature to use for splitting dataset\n",
    "        self.feature_index = feature_index\n",
    "        ## threshold value to split dataset\n",
    "        self.threshold = threshold\n",
    "        ## root node of the left subtree\n",
    "        self.left = left\n",
    "        ## root node of the left subtree\n",
    "        self.right = right\n",
    "        ## information gained from the this node\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # for leaf node\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        ''' constructor '''\n",
    "        \n",
    "        # initialize the root of the tree \n",
    "        self.root = None\n",
    "        \n",
    "        # stopping conditions\n",
    "        ## if number of data samples in dataset to split using build_tree cannot be \n",
    "        ## smaller than min_samples_split (default to 2 points)\n",
    "        self.min_samples_split = min_samples_split\n",
    "        ## building a tree with ever increasing depth as it recurses maximum depth of \n",
    "        ## a branch cannot exceed max_depth(default 3 levels if root node is included)\n",
    "\n",
    "        # TODO \n",
    "        # As the dataset is big, it is prone to overfitting, we are unlikely to \n",
    "        # split the dataset into less than min_samples_split. Hence, it is likely we should\n",
    "        # instead determin the max_depth of the tree. \n",
    "        # Hence making max_depth our HYPERPARAMETER\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' recursive function to build the tree ''' \n",
    "        \n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "        \n",
    "        # only split if sample is large enough or max depth is not exceeded\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            # find the best split\n",
    "            # returns a dictionary that characterises the best_split (with the most information gain) \n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            # check if information gain is positive\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                # recursion: build_tree on the left, left_subtree is the root node of the left subtree\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                # recursion: build_tree on the right, right_subtree is the root node of right subtree\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                # return current decision node (with inputs left node, right node and node attributes)\n",
    "                # not a leaf so no value\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        \n",
    "        # compute leaf node\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        # return leaf node\n",
    "        # only leaf node has value\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        ''' function to find the best split '''\n",
    "        \n",
    "        # dictionary to store the best split\n",
    "        best_split = {}\n",
    "        # max_info_gain from any decision threshold boundary to be negative infinity (monotonically increasing)  \n",
    "        max_info_gain = -float(\"inf\")\n",
    "        \n",
    "        # For each feature i\n",
    "        for feature_index in range(num_features):\n",
    "            # Finding unique values for a particular feature\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            # For every unique value/possible threshold in feature i, calculate the information gain\n",
    "            for threshold in possible_thresholds:\n",
    "                # get current split\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                # check if childs are not null\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    # compute information gain\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y)\n",
    "                    # update the best split if needed\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "                        \n",
    "        # return best split\n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        ''' function to split the data '''\n",
    "        \n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    # TODO\n",
    "    # Alternatively, entropy can be used instead of gini_index but because entropy is more computationally\n",
    "    # intensive so it was not used. Loss function can be considered a HYPERPARAMETER. Entropy criterion\n",
    "    # only performs marginally better but might be worth exploring\n",
    "    def information_gain(self, parent, l_child, r_child):\n",
    "        ''' function to compute information gain '''\n",
    "        \n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "       \n",
    "        return gain\n",
    "    \n",
    "    def gini_index(self, y):\n",
    "        ''' function to compute gini index '''\n",
    "\n",
    "        # Formula of gini index is 1 - summation((probability of class i)**2)\n",
    "        p1_sq = (len(y[y == 1]) / len(y))**2\n",
    "        p0_sq = (len(y[y == 0]) / len(y))**2\n",
    "        gini = 1- p1_sq - p0_sq\n",
    "\n",
    "        return gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):\n",
    "        ''' function to compute leaf node '''\n",
    "        \n",
    "        # value of leaf value == most commonly found class in the leaf within data \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    \n",
    "    def print_tree(self, tree=None, indent=\" \"):\n",
    "        ''' function to print the tree '''\n",
    "        \n",
    "        if not tree:\n",
    "            tree = self.root\n",
    "\n",
    "        if tree.value is not None:\n",
    "            print(tree.value)\n",
    "\n",
    "        else:\n",
    "            print(\"Feature: \"+str(tree.feature_index), \"<=\", tree.threshold, \",info_gain: \", tree.info_gain)\n",
    "            print(\"%sleft:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.left, indent + indent)\n",
    "            print(\"%sright:\" % (indent), end=\"\")\n",
    "            self.print_tree(tree.right, indent + indent)\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        ''' function to train the tree '''\n",
    "        \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' function to predict new dataset '''\n",
    "        \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, node):\n",
    "        ''' function to predict a single data point '''\n",
    "        \n",
    "        # If leaf node\n",
    "        if node.value!=None: \n",
    "            return node.value\n",
    "        # If not leaf node, need to determine whether to continue on the left or right node\n",
    "        feature_val = x[node.feature_index]\n",
    "        if feature_val<=node.threshold:\n",
    "            return self.make_prediction(x, node.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "#Need to use the dataset with reduced dimensions\n",
    "X = train_features.iloc[:, 10:20].values\n",
    "Y = train_features.iloc[:, 0].values.reshape(-1,1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1 <= 0.0 ,info_gain:  0.0002817556815680744\n",
      " left:Feature: 8 <= 0.0 ,info_gain:  0.00011559327255450391\n",
      "  left:Feature: 5 <= 0.5128646382061476 ,info_gain:  0.00011292045727268052\n",
      "    left:Feature: 5 <= 0.3070285320983342 ,info_gain:  0.0001859417935706209\n",
      "        left:Feature: 5 <= 0.2922486917420209 ,info_gain:  0.00013013016436252967\n",
      "                left:Feature: 5 <= 0.0 ,info_gain:  0.0001039601168097426\n",
      "                                left:Feature: 0 <= 0.4082405717900109 ,info_gain:  8.325308761020223e-05\n",
      "                                                                left:0.0\n",
      "                                                                right:0.0\n",
      "                                right:0.0\n",
      "                right:Feature: 5 <= 0.2994042317448218 ,info_gain:  0.05333333333333318\n",
      "                                left:1.0\n",
      "                                right:Feature: 5 <= 0.3019129309487226 ,info_gain:  0.4444444444444445\n",
      "                                                                left:0.0\n",
      "                                                                right:1.0\n",
      "        right:Feature: 9 <= 0.0 ,info_gain:  0.09295570079883812\n",
      "                left:Feature: 5 <= 0.3746284284824722 ,info_gain:  0.022491349480968786\n",
      "                                left:0.0\n",
      "                                right:Feature: 5 <= 0.4134531949494731 ,info_gain:  0.375\n",
      "                                                                left:1.0\n",
      "                                                                right:0.0\n",
      "                right:1.0\n",
      "    right:1.0\n",
      "  right:Feature: 8 <= 0.4285086181362184 ,info_gain:  0.17006802721088446\n",
      "    left:Feature: 8 <= 0.3640117456019299 ,info_gain:  0.05555555555555544\n",
      "        left:1.0\n",
      "        right:Feature: 8 <= 0.3877112269304498 ,info_gain:  0.4444444444444445\n",
      "                left:0.0\n",
      "                right:1.0\n",
      "    right:0.0\n",
      " right:1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=6)\n",
    "classifier.fit(X_train,Y_train)\n",
    "classifier.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6045970322956067"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = classifier.predict(X_test) \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Do cross validation so that machine learning model is performs more consistently. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f9328efe3468e6c370cdfed98702d3986faf748314d5bcec59da615d65baa7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
